{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eric Hong Naive Bayes ca02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCkDJFj4VZ32"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Cl22-eZ1-U"
      },
      "source": [
        "def make_dictionary(setup_dir):\r\n",
        "  #This function is a setup for the next function that trains my model\r\n",
        "  #loading in the emails from training directory\r\n",
        "  emails = [os.path.join(setup_dir,a) for a in os.listdir(setup_dir)]\r\n",
        "  #takes in all the words from every emails\r\n",
        "  all_words = []\r\n",
        "  for mail in emails:\r\n",
        "    with open(mail) as m:\r\n",
        "      for line in m:\r\n",
        "        #splits words on space to turn each word into an item \r\n",
        "        words = line.split()\r\n",
        "        #save each word as an item in the list created above\r\n",
        "        all_words += words\r\n",
        "  #Tallies up all the words that occured in all the mails combined\r\n",
        "  dictionary = Counter(all_words)\r\n",
        "  #print(type(dictionary)) - Dictionary is a counter type\r\n",
        "  #Turn dictionary into a list and save it to items_to_remove list to allow iteration in upcoming for loop\r\n",
        "  items_to_remove = list(dictionary)\r\n",
        "\r\n",
        "  for item in items_to_remove:\r\n",
        "    #Removes characters that are non alphabets\r\n",
        "    if item.isalpha() == False:\r\n",
        "      del dictionary[item]\r\n",
        "    #Removes any item that has length of 1 such as \"I, a, etc\"\r\n",
        "    elif len(item) == 1:\r\n",
        "      del dictionary[item]\r\n",
        "  #most_common returns 3000 items that are used the most and sorted from most to least\r\n",
        "  #format it returns in eg. Counter('Hello').most_common(2) it would return l, 2 and H, 1.\r\n",
        "  #'H' is prioritized over 'e' and 'o' because it came first.\r\n",
        "  dictionary = dictionary.most_common(3000)\r\n",
        "  #print(dictionary)\r\n",
        "  return dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiK3aTC3bvtl",
        "outputId": "b769e3d6-1be1-4334-a97b-3481a325d854"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiaC8SOobzEo"
      },
      "source": [
        "#This function is used to train the model, then test the accuracy of the gaussianNB that will be implemented below\r\n",
        "def extract_features(mail_dir):\r\n",
        "  #Joins path and creates a list with the files in specified directory\r\n",
        "  files = [os.path.join(mail_dir,b) for b in os.listdir(mail_dir)]\r\n",
        "  #sets up a features matrix with the rows being made of the number of files we will feed it\r\n",
        "  #and the columns consisting of the 3000 most common words that was determined in the previous function\r\n",
        "  features_matrix = np.zeros((len(files),3000))\r\n",
        "  #Used to label spam/non spam emails, filled with 0 and 1s and list size is the number of files we feed it with\r\n",
        "  training_labels = np.zeros(len(files))\r\n",
        "  #Starts from 1 because array position starts from 0\r\n",
        "  count = 1;\r\n",
        "  docID = 0;\r\n",
        "  for file in files:\r\n",
        "    #opening list of all the file names \r\n",
        "    with open(file) as b:\r\n",
        "      #It iterates through each line in the file and returns the line number and the content\r\n",
        "      for i, line in enumerate(b):\r\n",
        "        #Starts from line 3 (i==2) because that is where the mail content is located. this does not take content into account\r\n",
        "        if i ==2:\r\n",
        "          #separates each word through whitespaces and save it into a list named words\r\n",
        "          words = line.split()\r\n",
        "          #iterate through each word in the wordlist\r\n",
        "          for word in words:\r\n",
        "            #Loops through the words in the file, for each word we loop through each feature word in the dictionary\r\n",
        "            #If word from file is equal to one of the top 3000 words in dictionary, the feature matrix updates the # of occurence of that word in the feature matrix by the amount of times it appeared in the message\r\n",
        "            #Initializing wordID\r\n",
        "            wordID = 0\r\n",
        "            #enumerate iterates through dictionary index(i) and return key value pair (word and occurences)\r\n",
        "            for i, d in enumerate(dictionary):\r\n",
        "              #d is the tuple that contains the word and number of occurences\r\n",
        "              #d[0] is the word and d[1] is the number of occurences\r\n",
        "              #i iterates through each of the top 3000 word columns in the feature matrix\r\n",
        "              if d[0] == word:\r\n",
        "                #Indexing the wordID based on index in the dictionary to follow the words on the feature matrix columns\r\n",
        "                wordID = i\r\n",
        "                #Feature matrix updates the slot in the matrix based on the number of occurences of selected word in the file that is being read\r\n",
        "                features_matrix[docID,wordID] = words.count(word)\r\n",
        "      #Sets training label as non spam initially\r\n",
        "      training_labels[docID] = 0;\r\n",
        "      #Splits the file name on '/' into a word list\r\n",
        "      filepathTokens = file.split('/')\r\n",
        "      #Refers to the last word in the filepathtokens list \r\n",
        "      filename = filepathTokens[len(filepathTokens)-1]\r\n",
        "      #if file name starts with spmsg\r\n",
        "      if filename.startswith(\"spmsg\"):\r\n",
        "        #we would label it as spam\r\n",
        "        training_labels[docID] = 1;\r\n",
        "        #Number of spam mail increases by 1\r\n",
        "        count = count + 1\r\n",
        "      #After labelling the file, Iterate to the next file document and increases index by 1\r\n",
        "      docID = docID + 1\r\n",
        "  return features_matrix, training_labels    \r\n",
        "  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nDyaRZ-hN_S"
      },
      "source": [
        "TRAINING_DIR = '/content/drive/MyDrive/MSBA_Colab_2020/ML_Algorithms/CA02/test-mails'\r\n",
        "TESTING_DIR = '/content/drive/MyDrive/MSBA_Colab_2020/ML_Algorithms/CA02/train-mails'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE0XbGI9hRFl",
        "outputId": "0136ba43-ec8e-406d-9343-88d1f04f8449"
      },
      "source": [
        "dictionary = make_dictionary(TRAINING_DIR)\r\n",
        "\r\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\r\n",
        "features_matrix, labels = extract_features(TRAINING_DIR)\r\n",
        "test_features_matrix, test_labels = extract_features(TESTING_DIR)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#The Naive Bayes takes into account the occurences 3000 most common words along with the probability of the email being a spam mail in the feature matrix to label whether a mail is spam or not\r\n",
        "model = GaussianNB()\r\n",
        "\r\n",
        "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\r\n",
        "\r\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\r\n",
        "#On the GaussianNB documentation page, it mentioned that\r\n",
        "#\"This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.\"\r\n",
        "#My interpretation of what this algorithm randomly samples my training dataset to \r\n",
        "#fit a smaller pool and then it fits the testing data into these pools and label them\r\n",
        "\r\n",
        "\r\n",
        "# Fluctuation:\r\n",
        "# from gaussianNb, has method called partial fit that randomly samples from the input to train the model\r\n",
        "# due to the random sampling, the accuracy fluctutates around 90%\r\n",
        "model.fit(features_matrix, labels)\r\n",
        "print (\"Training completed\")\r\n",
        "print (\"testing trained model to predict Test Data labels\")\r\n",
        "predicted_labels = model.predict(test_features_matrix)\r\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\r\n",
        "print (accuracy_score(test_labels, predicted_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9501424501424501\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}